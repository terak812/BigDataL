{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a820c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape(data):\n",
    "    num_rows = data.count()\n",
    "    num_columns = len(data.columns)\n",
    "    print(f\"Shape: ({num_rows}, {num_columns})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "960a6ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # Ignores all warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e86c283b-b988-4e2c-9c0d-0bf144380b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e5c3c2d-b1e5-4638-8c6f-90c1920e51d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4165508c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/09 20:53:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('treecode').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29578e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('college.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e527d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- private: string (nullable = true)\n",
      " |-- apps: integer (nullable = true)\n",
      " |-- accept: integer (nullable = true)\n",
      " |-- enroll: integer (nullable = true)\n",
      " |-- top10perc: integer (nullable = true)\n",
      " |-- top25perc: integer (nullable = true)\n",
      " |-- f_undergrad: integer (nullable = true)\n",
      " |-- p_undergrad: integer (nullable = true)\n",
      " |-- outstate: integer (nullable = true)\n",
      " |-- room_board: integer (nullable = true)\n",
      " |-- books: integer (nullable = true)\n",
      " |-- personal: integer (nullable = true)\n",
      " |-- phd: integer (nullable = true)\n",
      " |-- terminal: integer (nullable = true)\n",
      " |-- s_f_ratio: double (nullable = true)\n",
      " |-- perc_alumni: integer (nullable = true)\n",
      " |-- expend: integer (nullable = true)\n",
      " |-- grad_rate: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e788255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (777, 18)\n"
     ]
    }
   ],
   "source": [
    "shape(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "758b669f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------+------+---------+---------+-----------+-----------+--------+----------+-----+--------+---+--------+---------+-----------+------+---------+\n",
      "|private|apps|accept|enroll|top10perc|top25perc|f_undergrad|p_undergrad|outstate|room_board|books|personal|phd|terminal|s_f_ratio|perc_alumni|expend|grad_rate|\n",
      "+-------+----+------+------+---------+---------+-----------+-----------+--------+----------+-----+--------+---+--------+---------+-----------+------+---------+\n",
      "|    Yes|1660|  1232|   721|       23|       52|       2885|        537|    7440|      3300|  450|    2200| 70|      78|     18.1|         12|  7041|       60|\n",
      "|    Yes|2186|  1924|   512|       16|       29|       2683|       1227|   12280|      6450|  750|    1500| 29|      30|     12.2|         16| 10527|       56|\n",
      "|    Yes|1428|  1097|   336|       22|       50|       1036|         99|   11250|      3750|  400|    1165| 53|      66|     12.9|         30|  8735|       54|\n",
      "+-------+----+------+------+---------+---------+-----------+-----------+--------+----------+-----+--------+---+--------+---------+-----------+------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cae19b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['private',\n",
       " 'apps',\n",
       " 'accept',\n",
       " 'enroll',\n",
       " 'top10perc',\n",
       " 'top25perc',\n",
       " 'f_undergrad',\n",
       " 'p_undergrad',\n",
       " 'outstate',\n",
       " 'room_board',\n",
       " 'books',\n",
       " 'personal',\n",
       " 'phd',\n",
       " 'terminal',\n",
       " 's_f_ratio',\n",
       " 'perc_alumni',\n",
       " 'expend',\n",
       " 'grad_rate']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32dae7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70666f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=['apps',\n",
    "               'accept',\n",
    "               'enroll',\n",
    "               'top10perc',\n",
    "               'top25perc',\n",
    "               'f_undergrad',\n",
    "               'p_undergrad',\n",
    "               'outstate',\n",
    "               'room_board',\n",
    "               'books',\n",
    "               'personal',\n",
    "               'phd',\n",
    "               'terminal',\n",
    "               's_f_ratio',\n",
    "               'perc_alumni',\n",
    "               'expend',\n",
    "               'grad_rate'],\n",
    "    outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56a929a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd3e350",
   "metadata": {},
   "source": [
    "### Deal with Private column \"yes\" or \"no\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe34221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol=\"private\", outputCol=\"privateIndex\")\n",
    "output_fixed = indexer.fit(output).transform(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9173f5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = output_fixed.select(\"features\", \"privateIndex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5d0218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = final_df.randomSplit([.7, .3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "075a7964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, GBTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41f717ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(labelCol='privateIndex', featuresCol='features')\n",
    "rfc = RandomForestClassifier(labelCol='privateIndex', featuresCol='features')\n",
    "gbt = GBTClassifier(labelCol='privateIndex', featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd794a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_model = dtc.fit(train_df)\n",
    "rfc_model = rfc.fit(train_df)\n",
    "gbt_model = gbt.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58309e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_predictions = dtc_model.transform(valid_df)\n",
    "rfc_predictions = rfc_model.transform(valid_df)\n",
    "gbt_predictions = gbt_model.transform(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6afb3c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e53bb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_evaluator = MulticlassClassificationEvaluator(labelCol='privateIndex',\n",
    "                                                  predictionCol='prediction',\n",
    "                                                  metricName='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "767fc072",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/09 20:53:23 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "25/07/09 20:53:23 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n"
     ]
    }
   ],
   "source": [
    "dtc_acc = acc_evaluator.evaluate(dtc_predictions)\n",
    "rfc_acc = acc_evaluator.evaluate(rfc_predictions)\n",
    "gbt_acc = acc_evaluator.evaluate(gbt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db8ab81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: \n",
      "--------------------------------------------------------------------------------\n",
      " A single decision tree - accuracy: 86.31%\n",
      "--------------------------------------------------------------------------------\n",
      " A random forest assemble - accuracy: 90.04%\n",
      "--------------------------------------------------------------------------------\n",
      " An ensemble using GBT - accuracy: 86.31%\n"
     ]
    }
   ],
   "source": [
    "print(\"Results: \")\n",
    "print('-'*80)\n",
    "print(' A single decision tree - accuracy: {0:2.2f}%'.format(dtc_acc*100))\n",
    "print('-'*80)\n",
    "print(' A random forest assemble - accuracy: {0:2.2f}%'.format(rfc_acc*100))\n",
    "print('-'*80)\n",
    "print(' An ensemble using GBT - accuracy: {0:2.2f}%'.format(gbt_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "874f0765",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'builtin_function_or_method' object has no attribute 'evaluate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m AUC \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(results)\n\u001b[1;32m      2\u001b[0m AUC\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'evaluate'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/09 20:53:31 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "AUC = eval.evaluate(results)\n",
    "AUC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
